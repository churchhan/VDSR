Step 1: Read test image by argument -i XXX.XXX(bmp or jpg should be fine). It is in RGB format and store it in ycbcr format as img_input

Need auxiliary function rgb2ycbcr in bitmap_helpers.cc

linkopts = ["-ljpeg"], need to be added to BUILD file if using #include <jpeglib.h>

For simplicity, we are using 41*41 size bmp or jpg file for test.



Step 2: Feed Y channel from img_input to sr.tflite (Model will be loaded by argument -m st.tflite) and generate enhanced Y channel en_Y 

sr.tflite was generated by regular trained tf model with tflite_converter:

In model training python file, use below command to generate graph file in .pbtxt:

saver.save(sess, "./checkpoints/VDSR_const_clip_0.01_epoch_%03d.ckpt" % epoch ,global_step=global_step)
tf.train.write_graph(sess.graph, '/home/jin/sr', 'test.pbtxt')

FYI: in model definition, name input and output tensors by: 

train_input, train_gt = q.dequeue_many(BATCH_SIZE)
input = tf.identity(train_input, name="input")

train_output, weights = shared_model(train_input)
out = tf.identity(train_output, name="out")

which will be used as identification for next steps. important (no need to output tensor names then)

then:

Before freeze graph, need to change the batch size to 1 and load the saved check point to generate new mode with input tensor shape as 1*41*41*1. If keep the old training model setting 64*41*41*1, the program will meet memory over boundary problem with sgpu acceleration. 

python /home/jin/tensorflow/tensorflow/python/tools/freeze_graph.py --input_graph /home/jin/sr/test.pbtxt --input_checkpoint /home/jin/sr/checkpoints/VDSR_const_clip_0.01_epoch_000.ckpt-1 --output_graph /home/jin/sr/freezed_graph.pbtxt --output_node_names out (Generate freezed graph in pbtxt file again) 

FYI: freeze_graph.py from tensorflow1.12 still did not support the new checkpoint format (tf1.12), has to use v1 checkpoint format

all tool from t1.12 might have the same issue (need further check)

tflite_convert --output_file=/home/jin/sr/sr.tflite --graph_def_file=/home/jin/sr/freezed_graph.pbtxt --input_arrays=input --output_arrays=out 

(Need adjustment later)



Step 3: Replace original Y channel of img_input with en_Y (Same method used by SRCNN for evaluation, believed SRVGG19 should use the same method to generate color image, but need to check how this method worked). The next step is transfer the result back to rgb and save it as img_input_HR.XXX

Need auxiliary function ycbcr2rgb in bitmap_helpers.cc
